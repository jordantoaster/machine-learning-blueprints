{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\jorda\\\\desktop\\\\machine-learning-blueprints\\\\env\\\\scripts\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity Methods\n",
    "\n",
    "When attempting to perform information retreival in the form of text matching it is important to consider two core ideas:\n",
    "\n",
    "1. Lexical Similarity\n",
    "2. Semantic Similarity.\n",
    "\n",
    "The former involves discovering text pairs that have the same meaning, even when none of the words in the text pairs are the same. This contextual understanding is what represents a good target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Sample Dataset - Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  We got this GPS for my husband who is an (OTR)...\n",
       "1  I'm a professional OTR truck driver, and I bou..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../../data/amazon-electronics-reviews.json', lines=True)\n",
    "df = df[['reviewText']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method #1 - Jaccard Similarity\n",
    "\n",
    "This represents typically lemmatising the words in the text pairs and calculating the outcome based on the lexical similarity. This would fail in cases such as the below:\n",
    "\n",
    "Sentence 1: President greets the press in Chicago\n",
    "\n",
    "Sentence 2: Obama speaks in Illinois\n",
    "\n",
    "These pairs represent the same intent, but would score poorly using the Jaccard score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Contextual Input Test Pair Based on Above Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = 'The president greets the press in Chicago'\n",
    "ss2 = 'Obama speaks to the media in Illinois'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - Cosine Similarity - Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  37.8 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6220355269907728"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def cosine_distance_countvectorizer_method(s1, s2):\n",
    "    \n",
    "    # sentences to list\n",
    "    allsentences = [s1 , s2]\n",
    "    \n",
    "    # text to vector\n",
    "    vectorizer = CountVectorizer()\n",
    "    all_sentences_to_vector = vectorizer.fit_transform(allsentences)\n",
    "    text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()\n",
    "    text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()\n",
    "    \n",
    "    # distance of similarity\n",
    "    cosine = distance.cosine(text_to_vector_v1, text_to_vector_v2)\n",
    "    print('Similarity of two sentences are equal to ',round((1-cosine)*100,2),'%')\n",
    "    return cosine\n",
    "\n",
    "cosine_distance_countvectorizer_method(ss1 , ss2)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "\n",
    "This method focuses only on the lexicon, not the context of words, which leads to a large cosine score. We want to see a score close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Cosine Distance Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.07999999999999996\n",
      "0.26887384498606903\n"
     ]
    }
   ],
   "source": [
    "v1 = [5,5,5,5,5]\n",
    "v2 = [3,7,3,7,3]\n",
    "v3 = [1,9,1,9,1]\n",
    "\n",
    "print(distance.cosine(v1, v1))\n",
    "print(distance.cosine(v1, v2))\n",
    "print(distance.cosine(v1, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see this is a score that increases the further apart the two input vectors are. Closer to 0 = better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 - Pre Trained Word Embeddings\n",
    "\n",
    "For Example, ‘President’ vs ‘Prime minister’, ‘Food’ vs ‘Dish’, ‘Hi’ vs ‘Hello’ should be considered similar. For this, converting the words into respective word vectors, and then, computing the similarities can address this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "    \n",
    "    # TODO - Add Stemmer / Lemma\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400001  words loaded!\n"
     ]
    }
   ],
   "source": [
    "gloveFile = \"../../data/glove.6B.100d.txt\"\n",
    "import numpy as np\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "model = loadGloveModel(gloveFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the 100 values within the vector representing 'hello' as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26688  ,  0.39632  ,  0.6169   , -0.77451  , -0.1039   ,\n",
       "        0.26697  ,  0.2788   ,  0.30992  ,  0.0054685, -0.085256 ,\n",
       "        0.73602  , -0.098432 ,  0.5479   , -0.030305 ,  0.33479  ,\n",
       "        0.14094  , -0.0070003,  0.32569  ,  0.22902  ,  0.46557  ,\n",
       "       -0.19531  ,  0.37491  , -0.7139   , -0.51775  ,  0.77039  ,\n",
       "        1.0881   , -0.66011  , -0.16234  ,  0.9119   ,  0.21046  ,\n",
       "        0.047494 ,  1.0019   ,  1.1133   ,  0.70094  , -0.08696  ,\n",
       "        0.47571  ,  0.1636   , -0.44469  ,  0.4469   , -0.93817  ,\n",
       "        0.013101 ,  0.085964 , -0.67456  ,  0.49662  , -0.037827 ,\n",
       "       -0.11038  , -0.28612  ,  0.074606 , -0.31527  , -0.093774 ,\n",
       "       -0.57069  ,  0.66865  ,  0.45307  , -0.34154  , -0.7166   ,\n",
       "       -0.75273  ,  0.075212 ,  0.57903  , -0.1191   , -0.11379  ,\n",
       "       -0.10026  ,  0.71341  , -1.1574   , -0.74026  ,  0.40452  ,\n",
       "        0.18023  ,  0.21449  ,  0.37638  ,  0.11239  , -0.53639  ,\n",
       "       -0.025092 ,  0.31886  , -0.25013  , -0.63283  , -0.011843 ,\n",
       "        1.377    ,  0.86013  ,  0.20476  , -0.36815  , -0.68874  ,\n",
       "        0.53512  , -0.46556  ,  0.27389  ,  0.4118   , -0.854    ,\n",
       "       -0.046288 ,  0.11304  , -0.27326  ,  0.15636  , -0.20334  ,\n",
       "        0.53586  ,  0.59784  ,  0.60469  ,  0.13735  ,  0.42232  ,\n",
       "       -0.61279  , -0.38486  ,  0.35842  , -0.48464  ,  0.30728  ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 77.15 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22852704995563478"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    s1 = preprocess(s1)\n",
    "    s2 = preprocess(s2)\n",
    "    \n",
    "    s1 = check_word_in_volcab(s1)\n",
    "    s2 = check_word_in_volcab(s2)\n",
    "    \n",
    "    vector_1 = np.mean([model[word] for word in s1],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in s2],axis=0)\n",
    "    \n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    print('Word Embedding method with a cosine distance assess that our two sentences are similar to',round((1-cosine)*100,2),'%')\n",
    "    return cosine\n",
    "\n",
    "\n",
    "def check_word_in_volcab(sentence):\n",
    "    avaliable_words = []\n",
    "    for word in sentence:\n",
    "        if word in model:\n",
    "            avaliable_words.append(word)\n",
    "    return avaliable_words\n",
    "\n",
    "        \n",
    "cosine_distance_wordembedding_method(ss1, ss2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This showcases for this example a signficant improvement in match quality using word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualise the embeddings at the word level..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2221273a278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cosine_distance_between_two_words(word1, word2):\n",
    "    return (1 - scipy.spatial.distance.cosine(model[word1], model[word2]))\n",
    "\n",
    "def calculate_heat_matrix_for_two_sentences(s1,s2):\n",
    "    s1 = preprocess(s1)\n",
    "    s2 = preprocess(s2)\n",
    "    result_list = [[cosine_distance_between_two_words(word1, word2) for word2 in s2] for word1 in s1]\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    result_df.columns = s2\n",
    "    result_df.index = s1\n",
    "    return result_df\n",
    "\n",
    "def heat_map_matrix_between_two_sentences(s1,s2):\n",
    "    df = calculate_heat_matrix_for_two_sentences(s1,s2)\n",
    "    fig, ax = plt.subplots(figsize=(5,5)) \n",
    "    ax_blue = sns.heatmap(df, cmap=\"YlGnBu\")\n",
    "    return ax_blue\n",
    "\n",
    "heat_map_matrix_between_two_sentences(ss1,ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22212ac67b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heat_map_matrix_between_two_sentences('hi, man','hello, woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Apply this method to a subset of our larger dataset to determine the closest review matches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a target Review (The first) and N others (seqeuntial)\n",
    "input_text = df[:1]['reviewText'].values[0]\n",
    "df_s = df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text # Lets check out our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 76.12 %\n",
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 93.06 %\n",
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 89.18 %\n",
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 93.87 %\n",
      "Word Embedding method with a cosine distance assess that our two sentences are similar to 96.11 %\n"
     ]
    }
   ],
   "source": [
    "# Apply a function onto df_s returning the match scores as a new column\n",
    "def similarity_score(sentence_a, sentence_b):\n",
    "    return cosine_distance_wordembedding_method(sentence_a, sentence_b)\n",
    "\n",
    "df_s['similarity'] =  df_s.apply(lambda x: similarity_score(x.reviewText, input_text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104082</th>\n",
       "      <td>bought these to install some speakers in my 1990 Mustang, they fit the speakers snugly and plug right into the factory wiring. Couldn't expect more.</td>\n",
       "      <td>0.238817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230080</th>\n",
       "      <td>I got this camera for my wife its her first digital camera and its a great entry level unit. Very easy to operate and takes nice photos. The price was right at just under a $100. I like that it uses AA bateries same as my Vivitar and uses the SD cards, the price on those are really dropping the 256 are $10. It came with the docking device, I may buy the printer, but we dont print a lot of photos. I like looking at them on the PC screeen or I transfer to a CD and watch on the TV.</td>\n",
       "      <td>0.069383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243135</th>\n",
       "      <td>For under $30, this is an awesome buy. No complaints about card performance. Seems to work excellently.</td>\n",
       "      <td>0.108249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223145</th>\n",
       "      <td>I bought this camera in May, it's my first \"real\" camera.  A few things I haven't seen mentioned: you can use at least a 4GB card, that was the largest when I bought the camera and it's working fine; there are add-on lenses, I just bought a wide angle and 2X telephoto, and I see there is also a 3X.  There's another lens you can buy for closeups.  All you need is the adaptor, you can also use filters and an external flash.This is a very versatile but easy-to-use camera.  I've talked to Canon Customer Support once (when I upgraded the memory card) and they were great, but have yet to read the manual.  There are all kinds of manual settings to play with, there is also a DVD tutorial available through Amazon that I'm thinking about.  Mostly I use automatic or portrait (blurs the background).  There's a Canon Yahoo group as well.Get a tripod if you are shooting in low light, those are the ones that come out blurry for me.  Video is sharp, but you can see how much I move ;-)  Someone earlier wanted a sports setting, try Kids&amp;Pets.;This is a great camera, the swivel screen is very cool and you'll be amazed at the shots you can get.  The more you learn, the more you can do.</td>\n",
       "      <td>0.061265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141739</th>\n",
       "      <td>I might be old fashioned but my grandparents had appliances that are still working 35 years after purchase. I think something like this simple device with no moving parts ought to last more than a year and a half. So I give it a star for each year it lived. I'm being generous with the half year. Now, I'm off to order a different brand.</td>\n",
       "      <td>0.038927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              reviewText  \\\n",
       "104082  bought these to install some speakers in my 1990 Mustang, they fit the speakers snugly and plug right into the factory wiring. Couldn't expect more.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "230080  I got this camera for my wife its her first digital camera and its a great entry level unit. Very easy to operate and takes nice photos. The price was right at just under a $100. I like that it uses AA bateries same as my Vivitar and uses the SD cards, the price on those are really dropping the 256 are $10. It came with the docking device, I may buy the printer, but we dont print a lot of photos. I like looking at them on the PC screeen or I transfer to a CD and watch on the TV.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "243135  For under $30, this is an awesome buy. No complaints about card performance. Seems to work excellently.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "223145  I bought this camera in May, it's my first \"real\" camera.  A few things I haven't seen mentioned: you can use at least a 4GB card, that was the largest when I bought the camera and it's working fine; there are add-on lenses, I just bought a wide angle and 2X telephoto, and I see there is also a 3X.  There's another lens you can buy for closeups.  All you need is the adaptor, you can also use filters and an external flash.This is a very versatile but easy-to-use camera.  I've talked to Canon Customer Support once (when I upgraded the memory card) and they were great, but have yet to read the manual.  There are all kinds of manual settings to play with, there is also a DVD tutorial available through Amazon that I'm thinking about.  Mostly I use automatic or portrait (blurs the background).  There's a Canon Yahoo group as well.Get a tripod if you are shooting in low light, those are the ones that come out blurry for me.  Video is sharp, but you can see how much I move ;-)  Someone earlier wanted a sports setting, try Kids&Pets.;This is a great camera, the swivel screen is very cool and you'll be amazed at the shots you can get.  The more you learn, the more you can do.   \n",
       "141739  I might be old fashioned but my grandparents had appliances that are still working 35 years after purchase. I think something like this simple device with no moving parts ought to last more than a year and a half. So I give it a star for each year it lived. I'm being generous with the half year. Now, I'm off to order a different brand.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "        similarity  \n",
       "104082  0.238817    \n",
       "230080  0.069383    \n",
       "243135  0.108249    \n",
       "223145  0.061265    \n",
       "141739  0.038927    "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "df_s.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4 - Soft Cosine Similarity with Fast Text Embeddings\n",
    "\n",
    "This also could technically work with Glove embeddings, but the gensim API exemplar was much simpler to implement as reference code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "from gensim.matutils import softcossim \n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Get the fast text embedding model\n",
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "documents = [ss1, ss2]\n",
    "\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(ss1))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(ss2))\n",
    "sentences = [sent_1, sent_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the similarity score between the two input sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6226904851163964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method to create a pandas matrix of similarities across several documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1.00  0.62\n",
       "1  0.62  1.00"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_soft_cossim_matrix(sentences):\n",
    "    len_array = np.arange(len(sentences))\n",
    "    xx, yy = np.meshgrid(len_array, len_array)\n",
    "    cossim_mat = pd.DataFrame([[round(softcossim(sentences[i],sentences[j], similarity_matrix) ,2) for i, j in zip(x,y)] for y, x in zip(xx, yy)])\n",
    "    return cossim_mat\n",
    "\n",
    "create_soft_cossim_matrix(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome\n",
    "\n",
    "The similarity score in this case is lower, but given we changed the word embedding method while using a soft cosine distance it does not directly yeild a fair comparison - revist indepedently in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5 - W2V + SIF - Google News Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for c in range(len([ss1, ss2])):\n",
    "    corpus[c] = pre_process(corpus[c])\n",
    "    \n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "feature_vectors = tfidf_vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Word2Vec embeddings, word will be represented as a multidimensional array. The two unsupervised algorithms, Skip-gram, and CBoW are used to generate word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word_emb_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIF Weighting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "def map_word_frequency(document):\n",
    "    return Counter(itertools.chain(*document))\n",
    "    \n",
    "def get_sif_feature_vectors(sentence1, sentence2, word_emb_model=word_emb_model):\n",
    "    sentence1 = [token for token in sentence1.split() if token in word_emb_model.wv.vocab]\n",
    "    sentence2 = [token for token in sentence2.split() if token in word_emb_model.wv.vocab]\n",
    "    word_counts = map_word_frequency((sentence1 + sentence2))\n",
    "    embedding_size = 300 # size of vectore in word embeddings\n",
    "    a = 0.001\n",
    "    sentence_set=[]\n",
    "    for sentence in [sentence1, sentence2]:\n",
    "        vs = np.zeros(embedding_size)\n",
    "        sentence_length = len(sentence)\n",
    "        for word in sentence:\n",
    "            a_value = a / (a + word_counts[word]) # smooth inverse frequency, SIF\n",
    "            vs = np.add(vs, np.multiply(a_value, word_emb_model.wv[word])) # vs += sif * word_vector\n",
    "        vs = np.divide(vs, sentence_length) # weighted average\n",
    "        sentence_set.append(vs)\n",
    "    return sentence_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "sentence_set = get_sif_feature_vectors(ss1, ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518640962891309"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cosine_similarity(sentence_set[0], sentence_set[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome\n",
    "\n",
    "Another sound implementation of a comparison appraoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5 - Doc2Vec - From Scratch\n",
    "\n",
    "This can be easily modified to be used on a custom dataset (internal / domain cases?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "data = [ss1, ss2]\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\gensim\\models\\doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "c:\\users\\jorda\\desktop\\machine-learning-blueprints\\env\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.00086425 -0.02024958 -0.00186852  0.0005197   0.01645884  0.01017107\n",
      "  0.00682817 -0.02136143  0.01324157  0.0106261   0.01132278  0.00468208\n",
      "  0.00891216  0.00951966 -0.01600788  0.01224463  0.0074051  -0.02235314\n",
      " -0.02260971  0.01266726]\n",
      "[('0', 0.9876613616943359)]\n",
      "[-0.09986771 -0.2762324   0.15846145  0.42846113  0.46483958 -0.08939951\n",
      " -0.63508695  0.20074709  0.03372648  0.13833457  0.17253941  0.06296055\n",
      " -0.27815953 -0.3078336   0.19920686 -0.5326984  -0.11055823  0.0959372\n",
      "  0.01647971 -0.03332953]\n"
     ]
    }
   ],
   "source": [
    "test_data = word_tokenize(\"Obama is speaking now\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n",
    "\n",
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
    "print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 6 - Universal Sentence Encoder.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 7 - BERT\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 8 - Siamese Neural Nets\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Perform a comparison on a reference open source data set (STS dataset)\n",
    "- BERT + Siamese Neural Nets + USE\n",
    "- Apply a given distance measure to all rows in a dataframe.\n",
    "- Bring in a TFIDF Variant as an additional basic benchmark.\n",
    "- Basic word2Vec variant to contrast with Glove.\n",
    "- Is it important to bring sentiment into play? contextual similarity + sentiment similarity?\n",
    "- Lacking cleaning / EDA analysis.\n",
    "- Does similarity need to also account for topics?\n",
    "- Once applied to all rows together you need a threshold defined in terms of reasonable cut off.\n",
    "- Consider a clustering approach.\n",
    "- We would need an open source test set and a domain test set, work with product to get a set of 500 pairs with some assigned sim score.\n",
    "- Use consistent distance or similarity score for cosine, currently I am jumping between both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://github.com/nlptown/nlp-notebooks/blob/master/Simple%20Sentence%20Similarity.ipynb\n",
    "    - Great reference code for various similarity measures.\n",
    "- https://medium.com/@adriensieg/text-similarities-da019229c894\n",
    "- https://github.com/adsieg/text_similarity\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://www.cs.toronto.edu/~lczhang/360/lec/w06/w2v.html\n",
    "- http://nlp.town/blog/sentence-similarity/\n",
    "    - references benchmarks and datasets to enable some comparison if required.\n",
    "- https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "- https://medium.com/@Intellica.AI/comparison-of-different-word-embeddings-on-text-similarity-a-use-case-in-nlp-e83e08469c1c#:~:text=Text%20Similarity%20is%20one%20of,perform%20any%20machine%20learning%20task.\n",
    "    - Really good article on w2v approach. Stresses importance of decision function and a domain test process\n",
    "- https://towardsdatascience.com/the-best-document-similarity-algorithm-in-2020-a-beginners-guide-a01b9ef8cf05\n",
    "- https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
